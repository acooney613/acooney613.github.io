---
layout: post
title:  "Simple Linear Regression in R, Python, and Julia"
author: Aidan Cooney
description: Performing a simple linear regression in 3 different programming languages.   
image: "/assets/images/python_on_a_beach.png"
---

## The Importance of Linear Regression:

Linear regression is an important concept to understand for those that wish to model any type of data. 
A simple linear regression refers to a method that is attempting to model the relationship between one variable 
Y with another variable X. This relationship allows for us to make predictions for Y based on the varying values of 
X. 

For this blog post, we will take a look at some example data, and how simple linear regression can be used to model 
the relationship between the two variables in three different programming languages. Knowing how to perform linear 
regression in multiple languages can help us see the potential differences or similarities, and analyze which may be 
the most effective or easiest to use. 

---
---

## Simple Linear Regression in R

The first programming language we are going to take a look at is R.

R is a common language for statistics based coding, and has tons of useful packages 
and functions built in for performing operations such as a simple linear regression. 

### Read in the data

To start, we first need to create some data, or read in the data we wish to analyze:

```

# create the data we will use to perform the simple linear regression
data <- data.frame(x = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
                   y = c(3, 5, 7, 9, 11, 13, 15, 17, 19, 21))

```

### Perform the Regression

Once you have read in the data (using the code shown above) you can begin your simple linear regression 
analysis. R has a built in function called 'lm()' which performs the regression for us. For our example,
we wish to model y using the x values. To do this  
in R, you do:

```

# perform the linear regression with y as the response variable and x as the explanatory
data.lm <- lm(y ~ x, data = data)

```

### Getting the Results

Now that we have our linear model we can use the 'summary()' function to see them. To do this in R,
use:

```

summary(data.lm)

```

This will return a large summary output with various values for residuals, as well as the R-squared and other 
helpful statistics. To look at the regression portion for our model, pay attention to the portion of the output 
that looks like this:

```

Coefficients:
             Estimate Std. Error   t value Pr(>|t|)    
(Intercept) 1.000e+00  1.034e-15 9.668e+14   <2e-16 ***
x           2.000e+00  1.667e-16 1.200e+16   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.514e-15 on 8 degrees of freedom
Multiple R-squared:      1,	Adjusted R-squared:      1 
F-statistic: 1.439e+32 on 1 and 8 DF,  p-value: < 2.2e-16

```

We can then use this output to see what the x coefficient is (Estimate for x is 2.000e+00), the intercept value is 1, and 
the significance of the x variable (Pr(>|t|)) is <2e-16. The R-squared value also shows us how well 
our model does at explaining the y variable.

Using the lm() is a simple and easy way to perform a simple linear regression in R, but what about python or julia?

## Simple Linear Regression in Python

The next programming language we are going to take a look at is python. 

Python is an extremely popular and useful language that is popular for those looking to do data science, and 
data analysis. But how does simple linear regression compare to the one performed in R?

### Read in the data

Unlike the R example, python does not have a built in function to perform linear regression. Instead, we first 
need to import some packages that will help us to create our model. If you do not already have these packages installed, you need to download them which can be done using pip install {package name}. The first package we need is a package called 
'numpy', which will allow us to read in our data in the necessary format. The second package we need is 'sklearn.linear_model' 
which will create our linear model for us. 

To do this in python run the following code:

```
import numpy as np
from sklearn.linear_model import LinearRegression


```

Now we can create the data we will use:

```

# the reshape is necessary for the use of the LinearRegression function later
x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)
y = np.array([3, 5, 7, 9, 11, 13, 15, 17, 19, 21])

```

### Perform the Regression

Once we have the data in the two arrays, we can use 'LinearRegression' to fit our model. 

To do this run the following code:

```

# fit model with x and y using LinearRegression()
model = LinearRegression().fit(x, y)

```

### Getting the Results

To get the results for this model, we must ask for the various pieces individuall. We can grab the 
x coefficient, the intercept, and the R-squared by running:

```

# prints the first coefficient (since we only have 1 it returns for the x variable)
print(model.coef_[0])

# prints the intercept value
print(model.intercept_)

# prints the R^2 value
print(model.score(x, y))


```

The output for this example should be:

```
2.0000000000000004
0.9999999999999982
1.0

```

Comparing these results to the results of the R 'lm()' function, we can see that we got the same R-squared value of 1, 
same x coefficient of about 2, and the same intercept value of about 1. This means that these models behave in a similar way, and either would be a good choice when looking to perform a simple linear regression. 


Now that we've performed the regression in both R and python let's see how it looks in julia.

## Simple Linear Regression in Julia

julia is a relatively new programming language, and does not have the strong footing that R or python has. julia was designed to combine the easy formatting of python with the speed and efficiency of C++. 

In this next section we are going to see what performing regression in julia would look like. 

### Read in the data

For julia, we first need to import Pkg, and ensure that we add 'DataFrames' and 'GLM' using the Pkg.add('') function. 

WARNING: make sure when you run the julia file that you comment out or remove the lines that contain Pkg.add('') as you do not need to add them again once you've done it once.

To read in the data using these import commands would look something like this:

```
import Pkg

#Pkg.add("DataFrames")
#Pkg.add("GLM")

using DataFrames, GLM

# create the data
data = DataFrame(
    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    y = [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]
)

```

### Perform the Regression

To perform the regression in julia, we do:

```

# create our model
lm_model = lm(@formula(y ~ x), data)

```

### Getting the Results

To get the results from our model, we use the code:

```
println(lm_model)

```

which should return this:

```

y ~ 1 + x

Coefficients:
─────────────────────────────────────────────────────────────────────────────────────
             Coef.   Std. Error                     t  Pr(>|t|)  Lower 95%  Upper 95%
─────────────────────────────────────────────────────────────────────────────────────
(Intercept)    1.0  7.73447e-16   1292914214144202.25    <1e-99        1.0        1.0
x              2.0  1.24652e-16  16044643449792320.00    <1e-99        2.0        2.0
─────────────────────────────────────────────────────────────────────────────────────

```

This output is very similar to the R summary output, and has the same x coefficient value as both python and R. This output does not contain an R-squared value, but does contain a 95% confidence interval. 


