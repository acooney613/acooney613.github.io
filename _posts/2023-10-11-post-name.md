---
layout: post
title:  "A Comparison Of Languagues: Simple Linear Regression in R, Python, and julia"
author: Aidan Cooney
description: A comparison of code required to perfrom a simple linear regression in R, Python and julia  
image: "/assets/images/python_on_a_beach.png"
---

## The Importance of Linear Regression:

Linear regression is an important tool to the world of data science. Using models to represent relationships in data is a valuable skill to any that hope to pursue data science. In this blog, we will cover how to fit a simple linear regression model in R, python, and julia so that you can add these this skill into your data science toolbelt. 

This blog is split up into three separate sections, one for each language. Each section uses the same data to fit the models. As we take a closer look at regression in these languages we will be able to see some similarities and differences in the way the code looks and runs.

---
---

## Simple Linear Regression in R

R programming first appeared in 1993, and has been a key player in the field of data science for a long time. R has tons of useful packages and functions for those looking at modeling and exploring data. We will use a function called 'lm()' in our example to fit our simple linear regression model. 

### Data

First we need to create the data we will use to fit our model using the code below:

CODE:
```
---
# create the data we will use to perform the simple linear regression
data <- data.frame(x = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
                   y = c(3, 5, 7, 9, 11, 13, 15, 17, 19, 21))
---
```

### Regression

Second we need to use the 'lm()' function to fit our regression model. The 'lm()' function takes several arguments, and for our case we will use the formula argument (y ~ x) and the data argumment (data = data) as shown below:

CODE:
```
---
# y as the response variable and x as the explanatory variable
data.lm <- lm(y ~ x, data = data)
---
```

### Results

Finally, we are able to grab our results. Using the 'summary()' function we can output a summary of the results of our model as seen below:

CODE:
```
---
summary(data.lm)
---
```

OUTPUT:
```
---
Coefficients:
             Estimate Std. Error   t value Pr(>|t|)    
(Intercept) 1.000e+00  1.034e-15 9.668e+14   <2e-16 ***
x           2.000e+00  1.667e-16 1.200e+16   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.514e-15 on 8 degrees of freedom
Multiple R-squared:      1,	Adjusted R-squared:      1 
F-statistic: 1.439e+32 on 1 and 8 DF,  p-value: < 2.2e-16
---
```

The output the 'summary()' function contains gives a lot of useful information. For comparisons with the other languages, we will focus on the Estimate values for x and the Intercept, the Mutiple R-squared value, and the Pr(>|t|). The Estimate values refer to the coefficients associated with the Intercept and x variable (which are 1 and 2 respectively). The R-squared value shows how well the model fits the data (received value of 1, meaning a perfect fit), and Pr(>|t|) is the significance of a particular variable for modeling y (we received <2e-16 for both).


Using the lm() is a simple and easy way to perform a simple linear regression in R, but what about python or julia?

## Simple Linear Regression in Python

Python was created in 1991, and is one of the most popular programming languages in the world. Whether you are a software developer or a data scientist knowing how to program in python is a valuable skill. For the data science community, python has many packages that have helpful functions and methods to represent and describe different kinds of data. For our example, we will explore the LinearRegression portion of the sklearn.linear_model package in performing simple linear regression.

### Data

Before we can start creating the data and fitting our model, we must import the packages we need to use the functions. For our example, we are importing numpy and LinearRegression. The code below shows how you would import these packages at the top of your file.

CODE:
```
---
import numpy as np
from sklearn.linear_model import LinearRegression
---
```

Once the packages are imported, we can create our data using the numpy package as shown below:

CODE:
```
---
# the reshape is necessary for the use of the LinearRegression function later
x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)
y = np.array([3, 5, 7, 9, 11, 13, 15, 17, 19, 21])
---
```

### Regression

Next we need to fit our model using the LinearRegression. Using our data, we make a call to the LinearRegression package and the give it the data we want to fit, with the explantory variable first and the response variable second, as shown below:

CODE:
```
---
# fit model with x and y using LinearRegression()
model = LinearRegression().fit(x, y)
---
```

### Results

Unlike the 'summary()' function in R, LinearRegression in python does not have a way to see all the data at once built in. Instead, we can access the bits and pieces we would like using the code below:

CODE:
```
---
# prints the first coefficient (since we only have 1 it returns for the x variable)

print(model.coef_[0])
# returns 2.0000000000000004

# prints the intercept value

print(model.intercept_)
# returns 0.9999999999999982

# prints the R-squared value

print(model.score(x, y))
# returns 1.0
---
```

The results from the R code and the python code are the same. We receive the same values for R-squared, coefficients, and intercept value (with some rounding). This means that both programming languages model this data similarly and can be good options for those looking at modeling data. 

Now that we've performed the regression in both R and python let's see how it looks in julia.

## Simple Linear Regression in julia

julia is the youngest of the three languages shown in this block, and was released in 2012. julia was designed to combine some of the syntax and functionality of python with the speed and efficiency of languages like C++. For our example, we will explore two extensions in julia that can be used to model data for a simple linear regression.

### Data

in julia, we need to import the main package (Pkg), and then add the extensions we need to create the data and model (DataFrames and GLM respectively). The code below shows how to add the extentions and create the data:

WARNING: make sure when you run the julia file that you comment out or remove the lines that contain Pkg.add('') as you do not need to add the extensions again as this takes up unnecessary time.

CODE:
```
---
import Pkg

Pkg.add("DataFrames") # comment out when added
Pkg.add("GLM") # comment out when added

using DataFrames, GLM

# create the data
data = DataFrame(
    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    y = [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]
)
---
```

### Regression

Fitting the model in julia, we need to use the 'lm' function similar to R, with the same two arguments (formula and data). In julia, however, we format the formula argument as '@formula(y ~ x)', which is different than the lm function in R:

CODE:
```
---
# create our model
lm_model = lm(@formula(y ~ x), data)
---
```

### Results

The results of our model output in a similar way to the 'summary()' function in R, but instead of summary we simply use 'println()' for our model:

CODE:
```
---
println(lm_model)
---
```

OUTPUT:
```
---
y ~ 1 + x

Coefficients:
─────────────────────────────────────────────────────────────────────────────────────
             Coef.   Std. Error                     t  Pr(>|t|)  Lower 95%  Upper 95%
─────────────────────────────────────────────────────────────────────────────────────
(Intercept)    1.0  7.73447e-16   1292914214144202.25    <1e-99        1.0        1.0
x              2.0  1.24652e-16  16044643449792320.00    <1e-99        2.0        2.0
─────────────────────────────────────────────────────────────────────────────────────
---
```

Looking at the output for the julia model, we can see that the coefficient values for x and the intercept are the same as both python and R's. This output however does not contain an R-squared value, but does contain confidence intervals. The Pr(>|t|) values are also slightly different, but both are extremely small. 

## Conclusion

Linear regression is a powerful tool in the world of data science, and knowing how to fit a model in several different languages is a valued skill for any data scientist. This blog showed how to fit simple linear regression models in R, python, and Julia and is a great stepping stone to using these languages for far more complex models.  

Linear regression is a powerful tool in the world of data science. Throughout this blog we covered how to perform a simple linear regression in R, python and julia. These examples are a great jumping off point for aspiring data scientists to practice their skills and become familiar with programming in languages such as these. This blog will hopefully help provide the framework for those looking at taking a deeper dive into the data science experience. 